#!/bin/bash

set -e

# This script takes in the direct RBM output files, creates a subdirectory under the RBM output directory, and put RBM results of each stream segment (each stream node has 2 segments; confluence grid cells have multiple nodes, while non-confluence grid cells have one node).
# Output file names: <lat>_<lon>_reach<reach#>_seg<seg#>
#    where <lat>, <lon> are lat and lon of the grid cell; 
#          <reach#> is the reach number defined in RBM (this can be helpful when trying to look at confluence grid cells);
#          <seg#> is the segment number (1 or 2)
# The columns of each file: <year> <day of year> <streamflow (cfs)> <stream T (degC)>

#=========================================================
# Parameter setting
#=========================================================
#=== input ===#
# We assume that direct RBM output files are: $rbm_output_dir/$run_code.Temp/.Spat
# A directory named $rbm_run_code will be made under the RBM output directory; formatted files will be under this directory
run_code=Yakima_Mabtom_1990_1995
rbm_output_dir=/raid2/ymao/VIC_RBM_east/VIC_RBM/model_run/output/RBM/Yakima_Mabtom  # RBM output directory

#=========================================================
# Processing
#=========================================================
temp=$rbm_output_dir/$run_code.Temp  # .Temp file
spat=$rbm_output_dir/$run_code.Spat  # .Spat file

# make directory for the formatted files
output_dir=$rbm_output_dir/$run_code
mkdir -p $output_dir
echo $output_dir

echo 'Counting data...'
nseg=`wc $spat | awk '{print $1}'`  # total number of all segments
nline_temp=` wc $temp | awk '{print $1}'` # number of lines in .Temp file
nday=`expr $nline_temp / $nseg`  # number of days

for ((i=1; i<=$nday; i++)); do  # loop over each day
	echo 'Processing day' $i '...';

	#=== extract data of one day ===#
	head -n `expr $i \* $nseg` $temp | tail -n $nseg > $output_dir/tmp_file

	#=== identify year and day ===#
	decimal_year=`head -n 1 $output_dir/tmp_file | awk '{print $1}'`
	year=$(echo $decimal_year | cut -f1 -d'.')
	day=`head -n 1 $output_dir/tmp_file | awk '{print $2}'`
	if [ $day -gt 360 ]; then
		if [ $(echo $decimal_year | cut -f2 -d'.') -eq '0013' ]; then
			year=$((year-1))
		fi
	fi

	#=== put data of this day to node/segment files ===#
	for ((j=1; j<=$nseg; j++)); do  # loop over each stream segment
		line=`head -n $j $spat | tail -n 1`  # the jth line in the .Spat file
		lat=$(echo $line | cut -f5 -d' ')
		lon=$(echo $line | cut -f6 -d' ')
		reach=$(echo $line | cut -f1 -d' ')
		seg=$(echo $line | cut -f7 -d' ')
		line_data=`head -n $j $output_dir/tmp_file | tail -n 1`  # the jth line in the tmp_file (should correspond to the same stream segment as the jth line in the .Spat file)
		flow=$(echo $line_data | cut -f9 -d' ')
		T_stream=$(echo $line_data | cut -f6 -d' ')
		if [ $i -eq 1 ]; then  # if the first day, create new file; add header
			echo 'year' 'day' 'flow' 'T_stream' > $output_dir/${lat}_${lon}_reach${reach}_seg${seg}
			echo $year $day $flow $T_stream >> $output_dir/${lat}_${lon}_reach${reach}_seg${seg}
		else  # if not the first day, append this day's data to existing file
			echo $year $day $flow $T_stream >> $output_dir/${lat}_${lon}_reach${reach}_seg${seg}
		fi
	done  # end of stream segment loop
done # end of day loop


#=========================================================
# Clean up
#=========================================================
rm -r $output_dir/tmp_file





